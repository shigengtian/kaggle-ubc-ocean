{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2cb761a2-0e8e-49c7-a954-9f32f546fe8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENCV_IO_MAX_IMAGE_PIXELS\"] = pow(2, 40).__str__()\n",
    "\n",
    "import gc\n",
    "import cv2\n",
    "import math\n",
    "import copy\n",
    "import time\n",
    "import random\n",
    "import glob\n",
    "import os, shutil\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# For data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Pytorch Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda import amp\n",
    "import torchvision\n",
    "\n",
    "# Utils\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "# For Image Models\n",
    "import timm\n",
    "from glob import glob\n",
    "\n",
    "# Albumentations for augmentations\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc623f1f-a183-4a98-a2ac-084a97808590",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    folds = 5\n",
    "    # size of the image\n",
    "    img_size = 512\n",
    "\n",
    "    # batch_size and epochs\n",
    "    batch_size = 16\n",
    "    num_workers = 4\n",
    "\n",
    "    # target column\n",
    "    target_cols = [\"CC\", \"EC\", \"HGSC\", \"LGSC\", \"MC\"]\n",
    "    \n",
    "    label_dict = {\n",
    "        0 : \"CC\",\n",
    "        1 : \"EC\",\n",
    "        2 : \"HGSC\",\n",
    "        3 : \"LGSC\",\n",
    "        4 : \"MC\"\n",
    "    }\n",
    "        \n",
    "    num_classes = len(target_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f557571-f6de-4d0d-9e29-29e2d7d1261d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "local = True\n",
    "if local:\n",
    "    data_dir = Path(\"dataset\")\n",
    "    test_thumbnails_path = data_dir / \"train_thumbnails\"\n",
    "    img_files = list(test_thumbnails_path.glob(\"*.png\"))\n",
    "    test_df = pd.DataFrame(img_files, columns=[\"thumbnails_file_paths\"])\n",
    "    test_df[\"image_id\"] = test_df[\"thumbnails_file_paths\"].apply(\n",
    "        lambda x: str(x).split(\"/\")[-1].split(\".\")[0].split(\"_\")[0]\n",
    "    )\n",
    "    \n",
    "    train_df = pd.read_csv(data_dir / \"train.csv\", dtype={\"image_id\": \"string\"})\n",
    "    test_df = test_df.merge(train_df, on=\"image_id\", how=\"left\")\n",
    "    \n",
    "    # test_df = pd.read_csv(data_dir / \"train.csv\")\n",
    "    # test_df[\"is_tma\"] =test_df[\"image_width\"] < 6000\n",
    "    test_df[\"file_path\"] = \"dataset/train_images/\" + test_df[\"image_id\"].astype(str) + \".png\"\n",
    "    # test_df[\"thumbnails_file_paths\"] = \"dataset/train_thumbnails/\" + test_df[\"image_id\"].astype(str) + \"_thumbnail.png\"  \n",
    "    \n",
    "else:\n",
    "    data_dir = Path(\"/kaggle/input/UBC-OCEAN\")\n",
    "    test_thumbnails_path = data_dir / \"test_thumbnails\"\n",
    "    test_df = pd.read_csv(data_dir / \"test.csv\")\n",
    "    test_df[\"is_tma\"] =test_df[\"image_width\"] < 6000\n",
    "    test_df[\"file_path\"] = \"/kaggle/input/UBC-OCEAN/test_images/\" + test_df[\"image_id\"].astype(str) + \".png\"\n",
    "    test_df[\"thumbnails_file_paths\"] = \"/kaggle/input/UBC-OCEAN/test_thumbnails/\" + test_df[\"image_id\"].astype(str) + \"_thumbnail.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab228735-ec9d-4188-b1dd-04e80d1b580e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>thumbnails_file_paths</th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "      <th>image_width</th>\n",
       "      <th>image_height</th>\n",
       "      <th>is_tma</th>\n",
       "      <th>file_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dataset/train_thumbnails/6175_thumbnail.png</td>\n",
       "      <td>6175</td>\n",
       "      <td>HGSC</td>\n",
       "      <td>60306</td>\n",
       "      <td>29620</td>\n",
       "      <td>False</td>\n",
       "      <td>dataset/train_images/6175.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dataset/train_thumbnails/27739_thumbnail.png</td>\n",
       "      <td>27739</td>\n",
       "      <td>HGSC</td>\n",
       "      <td>80170</td>\n",
       "      <td>41514</td>\n",
       "      <td>False</td>\n",
       "      <td>dataset/train_images/27739.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dataset/train_thumbnails/45254_thumbnail.png</td>\n",
       "      <td>45254</td>\n",
       "      <td>EC</td>\n",
       "      <td>62667</td>\n",
       "      <td>14444</td>\n",
       "      <td>False</td>\n",
       "      <td>dataset/train_images/45254.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dataset/train_thumbnails/51021_thumbnail.png</td>\n",
       "      <td>51021</td>\n",
       "      <td>HGSC</td>\n",
       "      <td>72720</td>\n",
       "      <td>37900</td>\n",
       "      <td>False</td>\n",
       "      <td>dataset/train_images/51021.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dataset/train_thumbnails/5251_thumbnail.png</td>\n",
       "      <td>5251</td>\n",
       "      <td>HGSC</td>\n",
       "      <td>105763</td>\n",
       "      <td>18704</td>\n",
       "      <td>False</td>\n",
       "      <td>dataset/train_images/5251.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dataset/train_thumbnails/286_thumbnail.png</td>\n",
       "      <td>286</td>\n",
       "      <td>EC</td>\n",
       "      <td>37204</td>\n",
       "      <td>30020</td>\n",
       "      <td>False</td>\n",
       "      <td>dataset/train_images/286.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dataset/train_thumbnails/30794_thumbnail.png</td>\n",
       "      <td>30794</td>\n",
       "      <td>HGSC</td>\n",
       "      <td>52389</td>\n",
       "      <td>38513</td>\n",
       "      <td>False</td>\n",
       "      <td>dataset/train_images/30794.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>dataset/train_thumbnails/16042_thumbnail.png</td>\n",
       "      <td>16042</td>\n",
       "      <td>HGSC</td>\n",
       "      <td>77563</td>\n",
       "      <td>26032</td>\n",
       "      <td>False</td>\n",
       "      <td>dataset/train_images/16042.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>dataset/train_thumbnails/1101_thumbnail.png</td>\n",
       "      <td>1101</td>\n",
       "      <td>HGSC</td>\n",
       "      <td>26306</td>\n",
       "      <td>18403</td>\n",
       "      <td>False</td>\n",
       "      <td>dataset/train_images/1101.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>dataset/train_thumbnails/3264_thumbnail.png</td>\n",
       "      <td>3264</td>\n",
       "      <td>HGSC</td>\n",
       "      <td>63480</td>\n",
       "      <td>28313</td>\n",
       "      <td>False</td>\n",
       "      <td>dataset/train_images/3264.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          thumbnails_file_paths image_id label  image_width  \\\n",
       "0   dataset/train_thumbnails/6175_thumbnail.png     6175  HGSC        60306   \n",
       "1  dataset/train_thumbnails/27739_thumbnail.png    27739  HGSC        80170   \n",
       "2  dataset/train_thumbnails/45254_thumbnail.png    45254    EC        62667   \n",
       "3  dataset/train_thumbnails/51021_thumbnail.png    51021  HGSC        72720   \n",
       "4   dataset/train_thumbnails/5251_thumbnail.png     5251  HGSC       105763   \n",
       "5    dataset/train_thumbnails/286_thumbnail.png      286    EC        37204   \n",
       "6  dataset/train_thumbnails/30794_thumbnail.png    30794  HGSC        52389   \n",
       "7  dataset/train_thumbnails/16042_thumbnail.png    16042  HGSC        77563   \n",
       "8   dataset/train_thumbnails/1101_thumbnail.png     1101  HGSC        26306   \n",
       "9   dataset/train_thumbnails/3264_thumbnail.png     3264  HGSC        63480   \n",
       "\n",
       "   image_height  is_tma                       file_path  \n",
       "0         29620   False   dataset/train_images/6175.png  \n",
       "1         41514   False  dataset/train_images/27739.png  \n",
       "2         14444   False  dataset/train_images/45254.png  \n",
       "3         37900   False  dataset/train_images/51021.png  \n",
       "4         18704   False   dataset/train_images/5251.png  \n",
       "5         30020   False    dataset/train_images/286.png  \n",
       "6         38513   False  dataset/train_images/30794.png  \n",
       "7         26032   False  dataset/train_images/16042.png  \n",
       "8         18403   False   dataset/train_images/1101.png  \n",
       "9         28313   False   dataset/train_images/3264.png  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = test_df[:10]\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "feecdbcb-84ad-4f54-8660-8b1f0b7dde5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed = 42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aafd308b-d8a3-49bf-9144-83040458d642",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class UBCSegDataset(Dataset):\n",
    "    def __init__(self, img_paths, transforms=None):\n",
    "        self.img_paths = img_paths\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        img_path = self.img_paths[index]\n",
    "\n",
    "        img = cv2.imread(str(img_path))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # image_id = self.image_ids[index]\n",
    "        \n",
    "        if self.transforms:\n",
    "            img = self.transforms(image=img)[\"image\"]\n",
    "            \n",
    "        return {\n",
    "            \"image\": img,\n",
    "        }\n",
    "    \n",
    "\n",
    "def seg_infer(df):\n",
    "    \n",
    "    _image_ids = []\n",
    "    _target_paths = []\n",
    "    \n",
    "    data_transforms = {\n",
    "        \"valid\": A.Compose([\n",
    "            A.Resize(CFG.img_size, CFG.img_size),\n",
    "            A.Normalize(\n",
    "                    mean=[0.485, 0.456, 0.406], \n",
    "                    std=[0.229, 0.224, 0.225], \n",
    "                    max_pixel_value=255.0, \n",
    "                    p=1.0\n",
    "                ),\n",
    "            ToTensorV2()], p=1.)\n",
    "    }\n",
    "\n",
    "    valid_dataset = UBCSegDataset(test_df, transforms=data_transforms[\"valid\"])\n",
    "\n",
    "    valid_loader = DataLoader(\n",
    "        valid_dataset,\n",
    "        batch_size=CFG.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=CFG.num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "    )\n",
    "    \n",
    "    model_name = \"efficientnet-b0\"\n",
    "    model_weight = \"exp-seg/seg-fold-0.pth\"\n",
    "    \n",
    "    model = smp.Unet(\n",
    "        encoder_name=model_name,\n",
    "        encoder_weights=None,\n",
    "        in_channels=3,\n",
    "        classes=1,\n",
    "        activation=None,\n",
    "    )\n",
    "\n",
    "    \n",
    "    model.to(device)\n",
    "    model.load_state_dict(torch.load(model_weight))\n",
    "    print(\"weights loaded\")\n",
    "\n",
    "    for index, data in enumerate(valid_loader):\n",
    "        images = data[\"image\"].to(device)\n",
    "        image_ids = data[\"image_id\"]\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(images)\n",
    "\n",
    "        probs = torch.sigmoid(outputs)\n",
    "        probs = probs.detach().cpu().numpy()\n",
    "\n",
    "        threshold = 0.50\n",
    "        binary_masks = (probs > threshold).astype(int)\n",
    "        for index, image_id in enumerate(image_ids):\n",
    "            _image_ids.append(str(image_id))\n",
    "            target_path = f\"infer_seg/{image_id}_seg.npy\"\n",
    "            _target_paths.append(target_path)\n",
    "            np.save(target_path, binary_masks[index][0])\n",
    "    \n",
    "#     rst = pd.DataFrame()\n",
    "#     rst[\"image_id\"] = _image_ids\n",
    "    df[\"seg_paths\"] = _target_paths\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8b6abafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(row):\n",
    "    image_id = row.image_id\n",
    "    image_path = row.file_path\n",
    "    is_tma = row.is_tma\n",
    "\n",
    "    img = cv2.imread(str(image_path))\n",
    "\n",
    "    height, width = img.shape[:2]\n",
    "    \n",
    "    img_target_path = Path(\"tiles\")\n",
    "    img_target_path.mkdir(parents=True, exist_ok=True)\n",
    "    tile_size = 2048\n",
    "    rows = height // tile_size\n",
    "    cols = width // tile_size\n",
    "\n",
    "    if is_tma:\n",
    "        print(\"is tma\")\n",
    "    else:\n",
    "        for i in range(rows):\n",
    "            for j in range(cols):                     \n",
    "                tile = img[\n",
    "                    i * tile_size: (i + 1) * tile_size,\n",
    "                    j * tile_size: (j + 1) * tile_size,\n",
    "                ]\n",
    " \n",
    "                tile_filename = f\"{image_id}_{i}_{j}.png\"\n",
    "                tile_path = img_target_path / tile_filename\n",
    "                cv2.imwrite(str(tile_path), tile)\n",
    "\n",
    "                del tile\n",
    "                gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "92b8cfb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/train_images/6175.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread QueueFeederThread:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/shigengtian/anaconda3/lib/python3.11/multiprocessing/queues.py\", line 239, in _feed\n",
      "    reader_close()\n",
      "  File \"/home/shigengtian/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 177, in close\n",
      "    self._close()\n",
      "  File \"/home/shigengtian/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 360, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/shigengtian/anaconda3/lib/python3.11/threading.py\", line 1038, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/shigengtian/anaconda3/lib/python3.11/threading.py\", line 975, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/shigengtian/anaconda3/lib/python3.11/multiprocessing/queues.py\", line 271, in _feed\n",
      "    queue_sem.release()\n",
      "ValueError: semaphore or lock released too many times\n"
     ]
    }
   ],
   "source": [
    "for index, row in test_df.iterrows():\n",
    "\n",
    "    print(row.file_path)\n",
    "    process_image(row)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abaa64f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tiles/6175_0_0.png',\n",
       " 'tiles/6175_0_1.png',\n",
       " 'tiles/6175_0_10.png',\n",
       " 'tiles/6175_0_11.png',\n",
       " 'tiles/6175_0_12.png',\n",
       " 'tiles/6175_0_13.png',\n",
       " 'tiles/6175_0_14.png',\n",
       " 'tiles/6175_0_15.png',\n",
       " 'tiles/6175_0_16.png',\n",
       " 'tiles/6175_0_17.png',\n",
       " 'tiles/6175_0_18.png',\n",
       " 'tiles/6175_0_19.png',\n",
       " 'tiles/6175_0_2.png',\n",
       " 'tiles/6175_0_20.png',\n",
       " 'tiles/6175_0_21.png',\n",
       " 'tiles/6175_0_22.png',\n",
       " 'tiles/6175_0_23.png',\n",
       " 'tiles/6175_0_24.png',\n",
       " 'tiles/6175_0_25.png',\n",
       " 'tiles/6175_0_26.png',\n",
       " 'tiles/6175_0_27.png',\n",
       " 'tiles/6175_0_28.png',\n",
       " 'tiles/6175_0_3.png',\n",
       " 'tiles/6175_0_4.png',\n",
       " 'tiles/6175_0_5.png',\n",
       " 'tiles/6175_0_6.png',\n",
       " 'tiles/6175_0_7.png',\n",
       " 'tiles/6175_0_8.png',\n",
       " 'tiles/6175_0_9.png',\n",
       " 'tiles/6175_10_0.png',\n",
       " 'tiles/6175_10_1.png',\n",
       " 'tiles/6175_10_10.png',\n",
       " 'tiles/6175_10_11.png',\n",
       " 'tiles/6175_10_12.png',\n",
       " 'tiles/6175_10_13.png',\n",
       " 'tiles/6175_10_14.png',\n",
       " 'tiles/6175_10_15.png',\n",
       " 'tiles/6175_10_16.png',\n",
       " 'tiles/6175_10_17.png',\n",
       " 'tiles/6175_10_18.png',\n",
       " 'tiles/6175_10_19.png',\n",
       " 'tiles/6175_10_2.png',\n",
       " 'tiles/6175_10_20.png',\n",
       " 'tiles/6175_10_21.png',\n",
       " 'tiles/6175_10_22.png',\n",
       " 'tiles/6175_10_23.png',\n",
       " 'tiles/6175_10_24.png',\n",
       " 'tiles/6175_10_25.png',\n",
       " 'tiles/6175_10_26.png',\n",
       " 'tiles/6175_10_27.png',\n",
       " 'tiles/6175_10_28.png',\n",
       " 'tiles/6175_10_3.png',\n",
       " 'tiles/6175_10_4.png',\n",
       " 'tiles/6175_10_5.png',\n",
       " 'tiles/6175_10_6.png',\n",
       " 'tiles/6175_10_7.png',\n",
       " 'tiles/6175_10_8.png',\n",
       " 'tiles/6175_10_9.png',\n",
       " 'tiles/6175_11_0.png',\n",
       " 'tiles/6175_11_1.png',\n",
       " 'tiles/6175_11_10.png',\n",
       " 'tiles/6175_11_11.png',\n",
       " 'tiles/6175_11_12.png',\n",
       " 'tiles/6175_11_13.png',\n",
       " 'tiles/6175_11_14.png',\n",
       " 'tiles/6175_11_15.png',\n",
       " 'tiles/6175_11_16.png',\n",
       " 'tiles/6175_11_17.png',\n",
       " 'tiles/6175_11_18.png',\n",
       " 'tiles/6175_11_19.png',\n",
       " 'tiles/6175_11_2.png',\n",
       " 'tiles/6175_11_20.png',\n",
       " 'tiles/6175_11_21.png',\n",
       " 'tiles/6175_11_22.png',\n",
       " 'tiles/6175_11_23.png',\n",
       " 'tiles/6175_11_24.png',\n",
       " 'tiles/6175_11_25.png',\n",
       " 'tiles/6175_11_26.png',\n",
       " 'tiles/6175_11_27.png',\n",
       " 'tiles/6175_11_28.png',\n",
       " 'tiles/6175_11_3.png',\n",
       " 'tiles/6175_11_4.png',\n",
       " 'tiles/6175_11_5.png',\n",
       " 'tiles/6175_11_6.png',\n",
       " 'tiles/6175_11_7.png',\n",
       " 'tiles/6175_11_8.png',\n",
       " 'tiles/6175_11_9.png',\n",
       " 'tiles/6175_12_0.png',\n",
       " 'tiles/6175_12_1.png',\n",
       " 'tiles/6175_12_10.png',\n",
       " 'tiles/6175_12_11.png',\n",
       " 'tiles/6175_12_12.png',\n",
       " 'tiles/6175_12_13.png',\n",
       " 'tiles/6175_12_14.png',\n",
       " 'tiles/6175_12_15.png',\n",
       " 'tiles/6175_12_16.png',\n",
       " 'tiles/6175_12_17.png',\n",
       " 'tiles/6175_12_18.png',\n",
       " 'tiles/6175_12_19.png',\n",
       " 'tiles/6175_12_2.png',\n",
       " 'tiles/6175_12_20.png',\n",
       " 'tiles/6175_12_21.png',\n",
       " 'tiles/6175_12_22.png',\n",
       " 'tiles/6175_12_23.png',\n",
       " 'tiles/6175_12_24.png',\n",
       " 'tiles/6175_12_25.png',\n",
       " 'tiles/6175_12_26.png',\n",
       " 'tiles/6175_12_27.png',\n",
       " 'tiles/6175_12_28.png',\n",
       " 'tiles/6175_12_3.png',\n",
       " 'tiles/6175_12_4.png',\n",
       " 'tiles/6175_12_5.png',\n",
       " 'tiles/6175_12_6.png',\n",
       " 'tiles/6175_12_7.png',\n",
       " 'tiles/6175_12_8.png',\n",
       " 'tiles/6175_12_9.png',\n",
       " 'tiles/6175_13_0.png',\n",
       " 'tiles/6175_13_1.png',\n",
       " 'tiles/6175_13_10.png',\n",
       " 'tiles/6175_13_11.png',\n",
       " 'tiles/6175_13_12.png',\n",
       " 'tiles/6175_13_13.png',\n",
       " 'tiles/6175_13_14.png',\n",
       " 'tiles/6175_13_15.png',\n",
       " 'tiles/6175_13_16.png',\n",
       " 'tiles/6175_13_17.png',\n",
       " 'tiles/6175_13_18.png',\n",
       " 'tiles/6175_13_19.png',\n",
       " 'tiles/6175_13_2.png',\n",
       " 'tiles/6175_13_20.png',\n",
       " 'tiles/6175_13_21.png',\n",
       " 'tiles/6175_13_22.png',\n",
       " 'tiles/6175_13_23.png',\n",
       " 'tiles/6175_13_24.png',\n",
       " 'tiles/6175_13_25.png',\n",
       " 'tiles/6175_13_26.png',\n",
       " 'tiles/6175_13_27.png',\n",
       " 'tiles/6175_13_28.png',\n",
       " 'tiles/6175_13_3.png',\n",
       " 'tiles/6175_13_4.png',\n",
       " 'tiles/6175_13_5.png',\n",
       " 'tiles/6175_13_6.png',\n",
       " 'tiles/6175_13_7.png',\n",
       " 'tiles/6175_13_8.png',\n",
       " 'tiles/6175_13_9.png',\n",
       " 'tiles/6175_1_0.png',\n",
       " 'tiles/6175_1_1.png',\n",
       " 'tiles/6175_1_10.png',\n",
       " 'tiles/6175_1_11.png',\n",
       " 'tiles/6175_1_12.png',\n",
       " 'tiles/6175_1_13.png',\n",
       " 'tiles/6175_1_14.png',\n",
       " 'tiles/6175_1_15.png',\n",
       " 'tiles/6175_1_16.png',\n",
       " 'tiles/6175_1_17.png',\n",
       " 'tiles/6175_1_18.png',\n",
       " 'tiles/6175_1_19.png',\n",
       " 'tiles/6175_1_2.png',\n",
       " 'tiles/6175_1_20.png',\n",
       " 'tiles/6175_1_21.png',\n",
       " 'tiles/6175_1_22.png',\n",
       " 'tiles/6175_1_23.png',\n",
       " 'tiles/6175_1_24.png',\n",
       " 'tiles/6175_1_25.png',\n",
       " 'tiles/6175_1_26.png',\n",
       " 'tiles/6175_1_27.png',\n",
       " 'tiles/6175_1_28.png',\n",
       " 'tiles/6175_1_3.png',\n",
       " 'tiles/6175_1_4.png',\n",
       " 'tiles/6175_1_5.png',\n",
       " 'tiles/6175_1_6.png',\n",
       " 'tiles/6175_1_7.png',\n",
       " 'tiles/6175_1_8.png',\n",
       " 'tiles/6175_1_9.png',\n",
       " 'tiles/6175_2_0.png',\n",
       " 'tiles/6175_2_1.png',\n",
       " 'tiles/6175_2_10.png',\n",
       " 'tiles/6175_2_11.png',\n",
       " 'tiles/6175_2_12.png',\n",
       " 'tiles/6175_2_13.png',\n",
       " 'tiles/6175_2_14.png',\n",
       " 'tiles/6175_2_15.png',\n",
       " 'tiles/6175_2_16.png',\n",
       " 'tiles/6175_2_17.png',\n",
       " 'tiles/6175_2_18.png',\n",
       " 'tiles/6175_2_19.png',\n",
       " 'tiles/6175_2_2.png',\n",
       " 'tiles/6175_2_20.png',\n",
       " 'tiles/6175_2_21.png',\n",
       " 'tiles/6175_2_22.png',\n",
       " 'tiles/6175_2_23.png',\n",
       " 'tiles/6175_2_24.png',\n",
       " 'tiles/6175_2_25.png',\n",
       " 'tiles/6175_2_26.png',\n",
       " 'tiles/6175_2_27.png',\n",
       " 'tiles/6175_2_28.png',\n",
       " 'tiles/6175_2_3.png',\n",
       " 'tiles/6175_2_4.png',\n",
       " 'tiles/6175_2_5.png',\n",
       " 'tiles/6175_2_6.png',\n",
       " 'tiles/6175_2_7.png',\n",
       " 'tiles/6175_2_8.png',\n",
       " 'tiles/6175_2_9.png',\n",
       " 'tiles/6175_3_0.png',\n",
       " 'tiles/6175_3_1.png',\n",
       " 'tiles/6175_3_10.png',\n",
       " 'tiles/6175_3_11.png',\n",
       " 'tiles/6175_3_12.png',\n",
       " 'tiles/6175_3_13.png',\n",
       " 'tiles/6175_3_14.png',\n",
       " 'tiles/6175_3_15.png',\n",
       " 'tiles/6175_3_16.png',\n",
       " 'tiles/6175_3_17.png',\n",
       " 'tiles/6175_3_18.png',\n",
       " 'tiles/6175_3_19.png',\n",
       " 'tiles/6175_3_2.png',\n",
       " 'tiles/6175_3_20.png',\n",
       " 'tiles/6175_3_21.png',\n",
       " 'tiles/6175_3_22.png',\n",
       " 'tiles/6175_3_23.png',\n",
       " 'tiles/6175_3_24.png',\n",
       " 'tiles/6175_3_25.png',\n",
       " 'tiles/6175_3_26.png',\n",
       " 'tiles/6175_3_27.png',\n",
       " 'tiles/6175_3_28.png',\n",
       " 'tiles/6175_3_3.png',\n",
       " 'tiles/6175_3_4.png',\n",
       " 'tiles/6175_3_5.png',\n",
       " 'tiles/6175_3_6.png',\n",
       " 'tiles/6175_3_7.png',\n",
       " 'tiles/6175_3_8.png',\n",
       " 'tiles/6175_3_9.png',\n",
       " 'tiles/6175_4_0.png',\n",
       " 'tiles/6175_4_1.png',\n",
       " 'tiles/6175_4_10.png',\n",
       " 'tiles/6175_4_11.png',\n",
       " 'tiles/6175_4_12.png',\n",
       " 'tiles/6175_4_13.png',\n",
       " 'tiles/6175_4_14.png',\n",
       " 'tiles/6175_4_15.png',\n",
       " 'tiles/6175_4_16.png',\n",
       " 'tiles/6175_4_17.png',\n",
       " 'tiles/6175_4_18.png',\n",
       " 'tiles/6175_4_19.png',\n",
       " 'tiles/6175_4_2.png',\n",
       " 'tiles/6175_4_20.png',\n",
       " 'tiles/6175_4_21.png',\n",
       " 'tiles/6175_4_22.png',\n",
       " 'tiles/6175_4_23.png',\n",
       " 'tiles/6175_4_24.png',\n",
       " 'tiles/6175_4_25.png',\n",
       " 'tiles/6175_4_26.png',\n",
       " 'tiles/6175_4_27.png',\n",
       " 'tiles/6175_4_28.png',\n",
       " 'tiles/6175_4_3.png',\n",
       " 'tiles/6175_4_4.png',\n",
       " 'tiles/6175_4_5.png',\n",
       " 'tiles/6175_4_6.png',\n",
       " 'tiles/6175_4_7.png',\n",
       " 'tiles/6175_4_8.png',\n",
       " 'tiles/6175_4_9.png',\n",
       " 'tiles/6175_5_0.png',\n",
       " 'tiles/6175_5_1.png',\n",
       " 'tiles/6175_5_10.png',\n",
       " 'tiles/6175_5_11.png',\n",
       " 'tiles/6175_5_12.png',\n",
       " 'tiles/6175_5_13.png',\n",
       " 'tiles/6175_5_14.png',\n",
       " 'tiles/6175_5_15.png',\n",
       " 'tiles/6175_5_16.png',\n",
       " 'tiles/6175_5_17.png',\n",
       " 'tiles/6175_5_18.png',\n",
       " 'tiles/6175_5_19.png',\n",
       " 'tiles/6175_5_2.png',\n",
       " 'tiles/6175_5_20.png',\n",
       " 'tiles/6175_5_21.png',\n",
       " 'tiles/6175_5_22.png',\n",
       " 'tiles/6175_5_23.png',\n",
       " 'tiles/6175_5_24.png',\n",
       " 'tiles/6175_5_25.png',\n",
       " 'tiles/6175_5_26.png',\n",
       " 'tiles/6175_5_27.png',\n",
       " 'tiles/6175_5_28.png',\n",
       " 'tiles/6175_5_3.png',\n",
       " 'tiles/6175_5_4.png',\n",
       " 'tiles/6175_5_5.png',\n",
       " 'tiles/6175_5_6.png',\n",
       " 'tiles/6175_5_7.png',\n",
       " 'tiles/6175_5_8.png',\n",
       " 'tiles/6175_5_9.png',\n",
       " 'tiles/6175_6_0.png',\n",
       " 'tiles/6175_6_1.png',\n",
       " 'tiles/6175_6_10.png',\n",
       " 'tiles/6175_6_11.png',\n",
       " 'tiles/6175_6_12.png',\n",
       " 'tiles/6175_6_13.png',\n",
       " 'tiles/6175_6_14.png',\n",
       " 'tiles/6175_6_15.png',\n",
       " 'tiles/6175_6_16.png',\n",
       " 'tiles/6175_6_17.png',\n",
       " 'tiles/6175_6_18.png',\n",
       " 'tiles/6175_6_19.png',\n",
       " 'tiles/6175_6_2.png',\n",
       " 'tiles/6175_6_20.png',\n",
       " 'tiles/6175_6_21.png',\n",
       " 'tiles/6175_6_22.png',\n",
       " 'tiles/6175_6_23.png',\n",
       " 'tiles/6175_6_24.png',\n",
       " 'tiles/6175_6_25.png',\n",
       " 'tiles/6175_6_26.png',\n",
       " 'tiles/6175_6_27.png',\n",
       " 'tiles/6175_6_28.png',\n",
       " 'tiles/6175_6_3.png',\n",
       " 'tiles/6175_6_4.png',\n",
       " 'tiles/6175_6_5.png',\n",
       " 'tiles/6175_6_6.png',\n",
       " 'tiles/6175_6_7.png',\n",
       " 'tiles/6175_6_8.png',\n",
       " 'tiles/6175_6_9.png',\n",
       " 'tiles/6175_7_0.png',\n",
       " 'tiles/6175_7_1.png',\n",
       " 'tiles/6175_7_10.png',\n",
       " 'tiles/6175_7_11.png',\n",
       " 'tiles/6175_7_12.png',\n",
       " 'tiles/6175_7_13.png',\n",
       " 'tiles/6175_7_14.png',\n",
       " 'tiles/6175_7_15.png',\n",
       " 'tiles/6175_7_16.png',\n",
       " 'tiles/6175_7_17.png',\n",
       " 'tiles/6175_7_18.png',\n",
       " 'tiles/6175_7_19.png',\n",
       " 'tiles/6175_7_2.png',\n",
       " 'tiles/6175_7_20.png',\n",
       " 'tiles/6175_7_21.png',\n",
       " 'tiles/6175_7_22.png',\n",
       " 'tiles/6175_7_23.png',\n",
       " 'tiles/6175_7_24.png',\n",
       " 'tiles/6175_7_25.png',\n",
       " 'tiles/6175_7_26.png',\n",
       " 'tiles/6175_7_27.png',\n",
       " 'tiles/6175_7_28.png',\n",
       " 'tiles/6175_7_3.png',\n",
       " 'tiles/6175_7_4.png',\n",
       " 'tiles/6175_7_5.png',\n",
       " 'tiles/6175_7_6.png',\n",
       " 'tiles/6175_7_7.png',\n",
       " 'tiles/6175_7_8.png',\n",
       " 'tiles/6175_7_9.png',\n",
       " 'tiles/6175_8_0.png',\n",
       " 'tiles/6175_8_1.png',\n",
       " 'tiles/6175_8_10.png',\n",
       " 'tiles/6175_8_11.png',\n",
       " 'tiles/6175_8_12.png',\n",
       " 'tiles/6175_8_13.png',\n",
       " 'tiles/6175_8_14.png',\n",
       " 'tiles/6175_8_15.png',\n",
       " 'tiles/6175_8_16.png',\n",
       " 'tiles/6175_8_17.png',\n",
       " 'tiles/6175_8_18.png',\n",
       " 'tiles/6175_8_19.png',\n",
       " 'tiles/6175_8_2.png',\n",
       " 'tiles/6175_8_20.png',\n",
       " 'tiles/6175_8_21.png',\n",
       " 'tiles/6175_8_22.png',\n",
       " 'tiles/6175_8_23.png',\n",
       " 'tiles/6175_8_24.png',\n",
       " 'tiles/6175_8_25.png',\n",
       " 'tiles/6175_8_26.png',\n",
       " 'tiles/6175_8_27.png',\n",
       " 'tiles/6175_8_28.png',\n",
       " 'tiles/6175_8_3.png',\n",
       " 'tiles/6175_8_4.png',\n",
       " 'tiles/6175_8_5.png',\n",
       " 'tiles/6175_8_6.png',\n",
       " 'tiles/6175_8_7.png',\n",
       " 'tiles/6175_8_8.png',\n",
       " 'tiles/6175_8_9.png',\n",
       " 'tiles/6175_9_0.png',\n",
       " 'tiles/6175_9_1.png',\n",
       " 'tiles/6175_9_10.png',\n",
       " 'tiles/6175_9_11.png',\n",
       " 'tiles/6175_9_12.png',\n",
       " 'tiles/6175_9_13.png',\n",
       " 'tiles/6175_9_14.png',\n",
       " 'tiles/6175_9_15.png',\n",
       " 'tiles/6175_9_16.png',\n",
       " 'tiles/6175_9_17.png',\n",
       " 'tiles/6175_9_18.png',\n",
       " 'tiles/6175_9_19.png',\n",
       " 'tiles/6175_9_2.png',\n",
       " 'tiles/6175_9_20.png',\n",
       " 'tiles/6175_9_21.png',\n",
       " 'tiles/6175_9_22.png',\n",
       " 'tiles/6175_9_23.png',\n",
       " 'tiles/6175_9_24.png',\n",
       " 'tiles/6175_9_25.png',\n",
       " 'tiles/6175_9_26.png',\n",
       " 'tiles/6175_9_27.png',\n",
       " 'tiles/6175_9_28.png',\n",
       " 'tiles/6175_9_3.png',\n",
       " 'tiles/6175_9_4.png',\n",
       " 'tiles/6175_9_5.png',\n",
       " 'tiles/6175_9_6.png',\n",
       " 'tiles/6175_9_7.png',\n",
       " 'tiles/6175_9_8.png',\n",
       " 'tiles/6175_9_9.png']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tile_files = sorted(glob(str(\"tiles/*.png\")))\n",
    "tile_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24f99dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84081000",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread QueueFeederThread:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/shigengtian/anaconda3/lib/python3.11/multiprocessing/queues.py\", line 239, in _feed\n",
      "Exception in thread QueueFeederThread:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/shigengtian/anaconda3/lib/python3.11/multiprocessing/queues.py\", line 239, in _feed\n",
      "    reader_close()\n",
      "  File \"/home/shigengtian/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 177, in close\n",
      "  File \"/home/shigengtian/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 177, in close\n",
      "    self._close()\n",
      "  File \"/home/shigengtian/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 360, in _close\n",
      "    self._close()\n",
      "  File \"/home/shigengtian/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 360, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/shigengtian/anaconda3/lib/python3.11/threading.py\", line 1038, in _bootstrap_inner\n",
      "Exception in thread QueueFeederThread:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/shigengtian/anaconda3/lib/python3.11/multiprocessing/queues.py\", line 240, in _feed\n",
      "    self.run()\n",
      "  File \"/home/shigengtian/anaconda3/lib/python3.11/threading.py\", line 975, in run\n",
      "    writer_close()\n",
      "  File \"/home/shigengtian/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 177, in close\n",
      "    self._close()\n",
      "  File \"/home/shigengtian/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 360, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/shigengtian/anaconda3/lib/python3.11/threading.py\", line 1038, in _bootstrap_inner\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/shigengtian/anaconda3/lib/python3.11/threading.py\", line 1038, in _bootstrap_inner\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/shigengtian/anaconda3/lib/python3.11/multiprocessing/queues.py\", line 271, in _feed\n",
      "    self.run()\n",
      "  File \"/home/shigengtian/anaconda3/lib/python3.11/threading.py\", line 975, in run\n",
      "    queue_sem.release()\n",
      "ValueError: semaphore or lock released too many times\n",
      "    self.run()\n",
      "  File \"/home/shigengtian/anaconda3/lib/python3.11/threading.py\", line 975, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/shigengtian/anaconda3/lib/python3.11/multiprocessing/queues.py\", line 271, in _feed\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/shigengtian/anaconda3/lib/python3.11/multiprocessing/queues.py\", line 271, in _feed\n",
      "    queue_sem.release()\n",
      "ValueError: semaphore or lock released too many times\n",
      "    queue_sem.release()\n",
      "ValueError: semaphore or lock released too many times\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights loaded\n"
     ]
    }
   ],
   "source": [
    "data_transforms = {\n",
    "    \"valid\": A.Compose([\n",
    "        A.Resize(CFG.img_size, CFG.img_size),\n",
    "        A.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406], \n",
    "                std=[0.229, 0.224, 0.225], \n",
    "                max_pixel_value=255.0, \n",
    "                p=1.0\n",
    "            ),\n",
    "        ToTensorV2()], p=1.)\n",
    "}\n",
    "\n",
    "\n",
    "valid_dataset = UBCSegDataset(tile_files, transforms=data_transforms[\"valid\"])\n",
    "\n",
    "valid_loader = DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size=CFG.batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=CFG.num_workers,\n",
    "    pin_memory=True,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "model_name = \"efficientnet-b0\"\n",
    "model_weight = \"exp-seg-2/seg-fold-0.pth\"\n",
    "\n",
    "model = smp.Unet(\n",
    "    encoder_name=model_name,\n",
    "    encoder_weights=None,\n",
    "    in_channels=3,\n",
    "    classes=1,\n",
    "    activation=None,\n",
    ")\n",
    "\n",
    "    \n",
    "model.to(device)\n",
    "model.load_state_dict(torch.load(model_weight))\n",
    "print(\"weights loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d249d56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/shigengtian/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3526, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_2286052/2060729563.py\", line 1, in <module>\n",
      "    for index, data in enumerate(valid_loader):\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/shigengtian/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 441, in __iter__\n",
      "    return self._get_iterator()\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/shigengtian/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 388, in _get_iterator\n",
      "    return _MultiProcessingDataLoaderIter(self)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/shigengtian/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1084, in __init__\n",
      "    self._reset(loader, first_iter=True)\n",
      "  File \"/home/shigengtian/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1117, in _reset\n",
      "    self._try_put_index()\n",
      "  File \"/home/shigengtian/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1351, in _try_put_index\n",
      "    index = self._next_index()\n",
      "            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/shigengtian/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 623, in _next_index\n",
      "    return next(self._sampler_iter)  # may raise StopIteration\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/shigengtian/anaconda3/lib/python3.11/site-packages/torch/utils/data/sampler.py\", line 254, in __iter__\n",
      "    for idx in self.sampler:\n",
      "  File \"/home/shigengtian/anaconda3/lib/python3.11/site-packages/torch/utils/data/sampler.py\", line 76, in __iter__\n",
      "    return iter(range(len(self.data_source)))\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_2286052/4121159660.py\", line 8, in __len__\n",
      "    return len(self.df)\n",
      "               ^^^^^^^\n",
      "AttributeError: 'UBCSegDataset' object has no attribute 'df'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/shigengtian/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 2120, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/shigengtian/anaconda3/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/shigengtian/anaconda3/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1326, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/shigengtian/anaconda3/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1173, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/shigengtian/anaconda3/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1063, in format_exception_as_a_whole\n",
      "    self.get_records(etb, number_of_lines_of_context, tb_offset) if etb else []\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/shigengtian/anaconda3/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1115, in get_records\n",
      "    style = stack_data.style_with_executing_node(style, self._tb_highlight)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/shigengtian/anaconda3/lib/python3.11/site-packages/stack_data/core.py\", line 424, in style_with_executing_node\n",
      "    class NewStyle(style):\n",
      "  File \"/home/shigengtian/anaconda3/lib/python3.11/site-packages/pygments/style.py\", line 91, in __new__\n",
      "    ndef[4] = colorformat(styledef[3:])\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/shigengtian/anaconda3/lib/python3.11/site-packages/pygments/style.py\", line 58, in colorformat\n",
      "    assert False, \"wrong color format %r\" % text\n",
      "AssertionError: wrong color format 'ansiyellow'\n"
     ]
    }
   ],
   "source": [
    "for index, data in enumerate(valid_loader):\n",
    "    image = data[\"image\"].to(device)\n",
    "    pred = model(image)\n",
    "    pred = torch.sigmoid(pred)\n",
    "    preds = pred.detach().cpu().numpy()\n",
    "            \n",
    "    threshold = 0.33\n",
    "    binary_masks = (preds > threshold).astype(int)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0e7011dc-c63d-4360-af4f-c1441a3c6c9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GeM(nn.Module):\n",
    "    def __init__(self, p=3, eps=1e-6):\n",
    "        super(GeM, self).__init__()\n",
    "        self.p = nn.Parameter(torch.ones(1)*p)\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.gem(x, p=self.p, eps=self.eps)\n",
    "        \n",
    "    def gem(self, x, p=3, eps=1e-6):\n",
    "        return F.avg_pool2d(x.clamp(min=eps).pow(p), (x.size(-2), x.size(-1))).pow(1./p)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + \\\n",
    "                '(' + 'p=' + '{:.4f}'.format(self.p.data.tolist()[0]) + \\\n",
    "                ', ' + 'eps=' + str(self.eps) + ')'\n",
    "    \n",
    "    \n",
    "class UBCModel(nn.Module):\n",
    "    def __init__(self, model_name, num_classes=5, pretrained=False, checkpoint_path=None):\n",
    "        super(UBCModel, self).__init__()\n",
    "        self.model = timm.create_model(model_name, pretrained=pretrained)\n",
    "\n",
    "        in_features = self.model.classifier.in_features\n",
    "        self.model.classifier = nn.Identity()\n",
    "        self.model.global_pool = nn.Identity()\n",
    "        self.pooling = GeM()\n",
    "        self.linear = nn.Linear(in_features, num_classes)\n",
    "#         self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, images):\n",
    "        features = self.model(images)\n",
    "        pooled_features = self.pooling(features).flatten(1)\n",
    "        output = self.linear(pooled_features)\n",
    "        return output\n",
    "    \n",
    "class UBCClcDataset(Dataset):\n",
    "    def __init__(self, df, transforms=None):\n",
    "        self.df = df\n",
    "        self.file_names = df[\"tile_file_paths\"].values\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.file_names[index]\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        if self.transforms:\n",
    "            img = self.transforms(image=img)[\"image\"]\n",
    "\n",
    "        return {\"image\": img}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0f96aa0f-978e-4775-b7e2-6ac26f5ade5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def infer_clc(tile_df, model):\n",
    "\n",
    "\n",
    "    def get_transforms():\n",
    "        return A.Compose(\n",
    "            [\n",
    "                A.Resize(CFG.img_size, CFG.img_size),\n",
    "                A.Normalize(\n",
    "                    mean=[0.485, 0.456, 0.406],\n",
    "                    std=[0.229, 0.224, 0.225],\n",
    "                    max_pixel_value=255.0,\n",
    "                    p=1.0,\n",
    "                ),\n",
    "                ToTensorV2(),\n",
    "            ],\n",
    "            p=1.0,\n",
    "        )\n",
    "\n",
    "    test_dataset = UBCClcDataset(tile_df, transforms=get_transforms())\n",
    "    test_loader = DataLoader(test_dataset, batch_size=4, \n",
    "                              num_workers=4, shuffle=False, pin_memory=True)\n",
    "    probs = []\n",
    "    for index, data in enumerate(test_loader):\n",
    "        data = data[\"image\"].to(device)\n",
    "        outputs = model(data)\n",
    "        p = torch.sigmoid(outputs)\n",
    "        p = p.detach().cpu().numpy()\n",
    "        probs.append(p)\n",
    "        \n",
    "        del data\n",
    "        del outputs\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "    probs = np.concatenate(probs)\n",
    "    probs = np.mean(probs,0)\n",
    "    max_index = np.argmax(probs)\n",
    "    \n",
    "    label_dict = {\n",
    "        0 : \"CC\",\n",
    "        1 : \"EC\",\n",
    "        2 : \"HGSC\",\n",
    "        3 : \"LGSC\",\n",
    "        4 : \"MC\"\n",
    "    }\n",
    "    \n",
    "    max_prob = probs[max_index]\n",
    "\n",
    "    if max_prob > 0.25:\n",
    "        pred_class = label_dict[max_index]\n",
    "    else:\n",
    "        pred_class = \"Other\"\n",
    "    return pred_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8885f418-6496-43c3-a415-c1a04ad26b1c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shigengtian/anaconda3/lib/python3.11/site-packages/timm/models/_factory.py:114: UserWarning: Mapping deprecated model name tf_efficientnetv2_s_in21ft1k to current tf_efficientnetv2_s.in21k_ft_in1k.\n",
      "  model = create_fn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights loaded\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "tile_size = 2048\n",
    "\n",
    "clc_weight = \"exp-06/fold-0.pth\"\n",
    "model = UBCModel(\"tf_efficientnetv2_s_in21ft1k\")\n",
    "model.to(device)\n",
    "model.load_state_dict(torch.load(clc_weight))\n",
    "print(\"weights loaded\")\n",
    "rst_image_ids = []\n",
    "rst_labels=[]\n",
    "for index, row in test_df.iterrows():\n",
    "    save_path = \"tiles\"\n",
    "\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    \n",
    "    _img_ids = []\n",
    "    _tile_file_paths = []\n",
    "    \n",
    "    image_id = row[\"image_id\"]\n",
    "    img_path = row[\"file_path\"]\n",
    "    mask_path = row[\"seg_paths\"]\n",
    "    is_tma = row[\"is_tma\"]\n",
    "    \n",
    "    \n",
    "    img = cv2.imread(str(img_path))\n",
    "    \n",
    "    height, width = img.shape[:2]\n",
    "    mask = np.load(str(mask_path))\n",
    "    mask = cv2.resize(mask, (width, height),interpolation=cv2.INTER_NEAREST)\n",
    "    \n",
    "    rows = height // tile_size\n",
    "    cols = width // tile_size\n",
    "    print(is_tma)\n",
    "#     if is_tma:\n",
    "#         tile = cv2.imread(img_path)\n",
    "#         tile = cv2.resize(tile, (512, 512), interpolation=cv2.INTER_NEAREST)\n",
    "#         tile_filename = f\"{image_id}.png\"\n",
    "#         tile_path = f\"{save_path}/{tile_filename}\"\n",
    "#         cv2.imwrite(tile_path, tile)\n",
    "#         _img_ids.append(image_id)\n",
    "#         _tile_file_paths.append(tile_path)\n",
    "#         del tile\n",
    "#         gc.collect()\n",
    "#         pass\n",
    "#     else:\n",
    "#         for i in range(rows):\n",
    "#             for j in range(cols):\n",
    "#                 tile_mask = mask[\n",
    "#                     i * tile_size : (i + 1) * tile_size,\n",
    "#                     j * tile_size : (j + 1) * tile_size,\n",
    "#                 ]\n",
    "#                 true_percentage = tile_mask.sum() / tile_mask.size\n",
    "#                 if true_percentage < 0.5:\n",
    "#                     continue\n",
    "\n",
    "#                 tile = img[\n",
    "#                     i * tile_size : (i + 1) * tile_size,\n",
    "#                     j * tile_size : (j + 1) * tile_size,\n",
    "#                 ]\n",
    "#                 tile = cv2.resize(tile, (512, 512), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "#                 tile_filename = f\"{image_id}_{i}_{j}.png\"\n",
    "#                 tile_path = f\"{save_path}/{tile_filename}\"\n",
    "#                 cv2.imwrite(tile_path, tile)\n",
    "#                 _img_ids.append(image_id)\n",
    "#                 _tile_file_paths.append(tile_path)\n",
    "#                 del tile\n",
    "#                 gc.collect()\n",
    "                \n",
    "                \n",
    "\n",
    "#     del img\n",
    "#     del mask\n",
    "#     gc.collect()\n",
    "    \n",
    "#     tile_df = pd.DataFrame()\n",
    "#     tile_df[\"image_id\"] = _img_ids\n",
    "#     tile_df[\"tile_file_paths\"] = _tile_file_paths\n",
    "#     print(tile_df)\n",
    "#     pred_class = infer_clc(tile_df, model)\n",
    "#     rst_image_ids.append(int(image_id))\n",
    "#     rst_labels.append(pred_class)\n",
    "#     shutil.rmtree(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7369ce-a033-4f7c-a58e-867148847e19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
