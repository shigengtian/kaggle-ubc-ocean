{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2cb761a2-0e8e-49c7-a954-9f32f546fe8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENCV_IO_MAX_IMAGE_PIXELS\"] = pow(2, 40).__str__()\n",
    "\n",
    "import gc\n",
    "import cv2\n",
    "import math\n",
    "import copy\n",
    "import time\n",
    "import random\n",
    "import glob\n",
    "import os, shutil\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# For data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Pytorch Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda import amp\n",
    "import torchvision\n",
    "\n",
    "# Utils\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "# For Image Models\n",
    "import timm\n",
    "from glob import glob\n",
    "\n",
    "# Albumentations for augmentations\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc623f1f-a183-4a98-a2ac-084a97808590",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    folds = 5\n",
    "    # size of the image\n",
    "    img_size = 512\n",
    "\n",
    "    # batch_size and epochs\n",
    "    batch_size = 16\n",
    "    num_workers = 4\n",
    "\n",
    "    # target column\n",
    "    target_cols = [\"CC\", \"EC\", \"HGSC\", \"LGSC\", \"MC\"]\n",
    "    \n",
    "    label_dict = {\n",
    "        0 : \"CC\",\n",
    "        1 : \"EC\",\n",
    "        2 : \"HGSC\",\n",
    "        3 : \"LGSC\",\n",
    "        4 : \"MC\"\n",
    "    }\n",
    "        \n",
    "    num_classes = len(target_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8f557571-f6de-4d0d-9e29-29e2d7d1261d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "local = True\n",
    "if local:\n",
    "    data_dir = Path(\"dataset\")\n",
    "    test_thumbnails_path = data_dir / \"train_thumbnails\"\n",
    "    img_files = list(test_thumbnails_path.glob(\"*.png\"))\n",
    "    test_df = pd.DataFrame(img_files, columns=[\"thumbnails_file_paths\"])\n",
    "    test_df[\"image_id\"] = test_df[\"thumbnails_file_paths\"].apply(\n",
    "        lambda x: str(x).split(\"/\")[-1].split(\".\")[0].split(\"_\")[0]\n",
    "    )\n",
    "    \n",
    "    train_df = pd.read_csv(data_dir / \"train.csv\", dtype={\"image_id\": \"string\"})\n",
    "    test_df = test_df.merge(train_df, on=\"image_id\", how=\"left\")\n",
    "    \n",
    "    # test_df = pd.read_csv(data_dir / \"train.csv\")\n",
    "    # test_df[\"is_tma\"] =test_df[\"image_width\"] < 6000\n",
    "    test_df[\"file_path\"] = \"dataset/train_images/\" + test_df[\"image_id\"].astype(str) + \".png\"\n",
    "    # test_df[\"thumbnails_file_paths\"] = \"dataset/train_thumbnails/\" + test_df[\"image_id\"].astype(str) + \"_thumbnail.png\"  \n",
    "    \n",
    "else:\n",
    "    data_dir = Path(\"/kaggle/input/UBC-OCEAN\")\n",
    "    test_thumbnails_path = data_dir / \"test_thumbnails\"\n",
    "    test_df = pd.read_csv(data_dir / \"test.csv\")\n",
    "    test_df[\"is_tma\"] =test_df[\"image_width\"] < 6000\n",
    "    test_df[\"file_path\"] = \"/kaggle/input/UBC-OCEAN/test_images/\" + test_df[\"image_id\"].astype(str) + \".png\"\n",
    "    test_df[\"thumbnails_file_paths\"] = \"/kaggle/input/UBC-OCEAN/test_thumbnails/\" + test_df[\"image_id\"].astype(str) + \"_thumbnail.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ab228735-ec9d-4188-b1dd-04e80d1b580e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>thumbnails_file_paths</th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "      <th>image_width</th>\n",
       "      <th>image_height</th>\n",
       "      <th>is_tma</th>\n",
       "      <th>file_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dataset/train_thumbnails/6175_thumbnail.png</td>\n",
       "      <td>6175</td>\n",
       "      <td>HGSC</td>\n",
       "      <td>60306</td>\n",
       "      <td>29620</td>\n",
       "      <td>False</td>\n",
       "      <td>dataset/train_images/6175.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dataset/train_thumbnails/27739_thumbnail.png</td>\n",
       "      <td>27739</td>\n",
       "      <td>HGSC</td>\n",
       "      <td>80170</td>\n",
       "      <td>41514</td>\n",
       "      <td>False</td>\n",
       "      <td>dataset/train_images/27739.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dataset/train_thumbnails/45254_thumbnail.png</td>\n",
       "      <td>45254</td>\n",
       "      <td>EC</td>\n",
       "      <td>62667</td>\n",
       "      <td>14444</td>\n",
       "      <td>False</td>\n",
       "      <td>dataset/train_images/45254.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dataset/train_thumbnails/51021_thumbnail.png</td>\n",
       "      <td>51021</td>\n",
       "      <td>HGSC</td>\n",
       "      <td>72720</td>\n",
       "      <td>37900</td>\n",
       "      <td>False</td>\n",
       "      <td>dataset/train_images/51021.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dataset/train_thumbnails/5251_thumbnail.png</td>\n",
       "      <td>5251</td>\n",
       "      <td>HGSC</td>\n",
       "      <td>105763</td>\n",
       "      <td>18704</td>\n",
       "      <td>False</td>\n",
       "      <td>dataset/train_images/5251.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>dataset/train_thumbnails/5114_thumbnail.png</td>\n",
       "      <td>5114</td>\n",
       "      <td>HGSC</td>\n",
       "      <td>33646</td>\n",
       "      <td>29171</td>\n",
       "      <td>False</td>\n",
       "      <td>dataset/train_images/5114.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>dataset/train_thumbnails/47105_thumbnail.png</td>\n",
       "      <td>47105</td>\n",
       "      <td>EC</td>\n",
       "      <td>39020</td>\n",
       "      <td>39353</td>\n",
       "      <td>False</td>\n",
       "      <td>dataset/train_images/47105.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>dataset/train_thumbnails/18196_thumbnail.png</td>\n",
       "      <td>18196</td>\n",
       "      <td>HGSC</td>\n",
       "      <td>64620</td>\n",
       "      <td>28043</td>\n",
       "      <td>False</td>\n",
       "      <td>dataset/train_images/18196.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>dataset/train_thumbnails/64111_thumbnail.png</td>\n",
       "      <td>64111</td>\n",
       "      <td>HGSC</td>\n",
       "      <td>15549</td>\n",
       "      <td>8129</td>\n",
       "      <td>False</td>\n",
       "      <td>dataset/train_images/64111.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>dataset/train_thumbnails/45630_thumbnail.png</td>\n",
       "      <td>45630</td>\n",
       "      <td>EC</td>\n",
       "      <td>65872</td>\n",
       "      <td>46075</td>\n",
       "      <td>False</td>\n",
       "      <td>dataset/train_images/45630.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>513 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            thumbnails_file_paths image_id label  image_width  \\\n",
       "0     dataset/train_thumbnails/6175_thumbnail.png     6175  HGSC        60306   \n",
       "1    dataset/train_thumbnails/27739_thumbnail.png    27739  HGSC        80170   \n",
       "2    dataset/train_thumbnails/45254_thumbnail.png    45254    EC        62667   \n",
       "3    dataset/train_thumbnails/51021_thumbnail.png    51021  HGSC        72720   \n",
       "4     dataset/train_thumbnails/5251_thumbnail.png     5251  HGSC       105763   \n",
       "..                                            ...      ...   ...          ...   \n",
       "508   dataset/train_thumbnails/5114_thumbnail.png     5114  HGSC        33646   \n",
       "509  dataset/train_thumbnails/47105_thumbnail.png    47105    EC        39020   \n",
       "510  dataset/train_thumbnails/18196_thumbnail.png    18196  HGSC        64620   \n",
       "511  dataset/train_thumbnails/64111_thumbnail.png    64111  HGSC        15549   \n",
       "512  dataset/train_thumbnails/45630_thumbnail.png    45630    EC        65872   \n",
       "\n",
       "     image_height  is_tma                       file_path  \n",
       "0           29620   False   dataset/train_images/6175.png  \n",
       "1           41514   False  dataset/train_images/27739.png  \n",
       "2           14444   False  dataset/train_images/45254.png  \n",
       "3           37900   False  dataset/train_images/51021.png  \n",
       "4           18704   False   dataset/train_images/5251.png  \n",
       "..            ...     ...                             ...  \n",
       "508         29171   False   dataset/train_images/5114.png  \n",
       "509         39353   False  dataset/train_images/47105.png  \n",
       "510         28043   False  dataset/train_images/18196.png  \n",
       "511          8129   False  dataset/train_images/64111.png  \n",
       "512         46075   False  dataset/train_images/45630.png  \n",
       "\n",
       "[513 rows x 7 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "feecdbcb-84ad-4f54-8660-8b1f0b7dde5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed = 42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "aafd308b-d8a3-49bf-9144-83040458d642",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class UBCSegDataset(Dataset):\n",
    "    def __init__(self, df, transforms=None):\n",
    "        self.df = df\n",
    "        self.image_ids = df[\"image_id\"].values\n",
    "        self.file_names = df['thumbnails_file_paths'].values\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        img_path = self.file_names[index]\n",
    "\n",
    "        img = cv2.imread(str(img_path))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        image_id = self.image_ids[index]\n",
    "        \n",
    "        if self.transforms:\n",
    "            img = self.transforms(image=img)[\"image\"]\n",
    "            \n",
    "        return {\n",
    "            \"image_id\": image_id,\n",
    "            \"image\": img,\n",
    "        }\n",
    "    \n",
    "\n",
    "def seg_infer(df):\n",
    "    \n",
    "    _image_ids = []\n",
    "    _target_paths = []\n",
    "    \n",
    "    data_transforms = {\n",
    "        \"valid\": A.Compose([\n",
    "            A.Resize(CFG.img_size, CFG.img_size),\n",
    "            A.Normalize(\n",
    "                    mean=[0.485, 0.456, 0.406], \n",
    "                    std=[0.229, 0.224, 0.225], \n",
    "                    max_pixel_value=255.0, \n",
    "                    p=1.0\n",
    "                ),\n",
    "            ToTensorV2()], p=1.)\n",
    "    }\n",
    "\n",
    "    valid_dataset = UBCSegDataset(test_df, transforms=data_transforms[\"valid\"])\n",
    "\n",
    "    valid_loader = DataLoader(\n",
    "        valid_dataset,\n",
    "        batch_size=CFG.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=CFG.num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "    )\n",
    "    \n",
    "    model_name = \"efficientnet-b0\"\n",
    "    model_weight = \"exp-seg/seg-fold-0.pth\"\n",
    "    \n",
    "    model = smp.Unet(\n",
    "        encoder_name=model_name,\n",
    "        encoder_weights=None,\n",
    "        in_channels=3,\n",
    "        classes=1,\n",
    "        activation=None,\n",
    "    )\n",
    "\n",
    "    \n",
    "    model.to(device)\n",
    "    model.load_state_dict(torch.load(model_weight))\n",
    "    print(\"weights loaded\")\n",
    "\n",
    "    for index, data in enumerate(valid_loader):\n",
    "        images = data[\"image\"].to(device)\n",
    "        image_ids = data[\"image_id\"]\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(images)\n",
    "\n",
    "        probs = torch.sigmoid(outputs)\n",
    "        probs = probs.detach().cpu().numpy()\n",
    "\n",
    "        threshold = 0.50\n",
    "        binary_masks = (probs > threshold).astype(int)\n",
    "        for index, image_id in enumerate(image_ids):\n",
    "            _image_ids.append(str(image_id))\n",
    "            target_path = f\"infer_seg/{image_id}_seg.npy\"\n",
    "            _target_paths.append(target_path)\n",
    "            np.save(target_path, binary_masks[index][0])\n",
    "    \n",
    "#     rst = pd.DataFrame()\n",
    "#     rst[\"image_id\"] = _image_ids\n",
    "    df[\"seg_paths\"] = _target_paths\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a3c433b0-d815-406a-b5ff-71f6390e7da9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights loaded\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>thumbnails_file_paths</th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "      <th>image_width</th>\n",
       "      <th>image_height</th>\n",
       "      <th>is_tma</th>\n",
       "      <th>file_path</th>\n",
       "      <th>seg_paths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dataset/train_thumbnails/6175_thumbnail.png</td>\n",
       "      <td>6175</td>\n",
       "      <td>HGSC</td>\n",
       "      <td>60306</td>\n",
       "      <td>29620</td>\n",
       "      <td>False</td>\n",
       "      <td>dataset/train_images/6175.png</td>\n",
       "      <td>infer_seg/6175_seg.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dataset/train_thumbnails/27739_thumbnail.png</td>\n",
       "      <td>27739</td>\n",
       "      <td>HGSC</td>\n",
       "      <td>80170</td>\n",
       "      <td>41514</td>\n",
       "      <td>False</td>\n",
       "      <td>dataset/train_images/27739.png</td>\n",
       "      <td>infer_seg/27739_seg.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dataset/train_thumbnails/45254_thumbnail.png</td>\n",
       "      <td>45254</td>\n",
       "      <td>EC</td>\n",
       "      <td>62667</td>\n",
       "      <td>14444</td>\n",
       "      <td>False</td>\n",
       "      <td>dataset/train_images/45254.png</td>\n",
       "      <td>infer_seg/45254_seg.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dataset/train_thumbnails/51021_thumbnail.png</td>\n",
       "      <td>51021</td>\n",
       "      <td>HGSC</td>\n",
       "      <td>72720</td>\n",
       "      <td>37900</td>\n",
       "      <td>False</td>\n",
       "      <td>dataset/train_images/51021.png</td>\n",
       "      <td>infer_seg/51021_seg.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dataset/train_thumbnails/5251_thumbnail.png</td>\n",
       "      <td>5251</td>\n",
       "      <td>HGSC</td>\n",
       "      <td>105763</td>\n",
       "      <td>18704</td>\n",
       "      <td>False</td>\n",
       "      <td>dataset/train_images/5251.png</td>\n",
       "      <td>infer_seg/5251_seg.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>dataset/train_thumbnails/5114_thumbnail.png</td>\n",
       "      <td>5114</td>\n",
       "      <td>HGSC</td>\n",
       "      <td>33646</td>\n",
       "      <td>29171</td>\n",
       "      <td>False</td>\n",
       "      <td>dataset/train_images/5114.png</td>\n",
       "      <td>infer_seg/5114_seg.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>dataset/train_thumbnails/47105_thumbnail.png</td>\n",
       "      <td>47105</td>\n",
       "      <td>EC</td>\n",
       "      <td>39020</td>\n",
       "      <td>39353</td>\n",
       "      <td>False</td>\n",
       "      <td>dataset/train_images/47105.png</td>\n",
       "      <td>infer_seg/47105_seg.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>dataset/train_thumbnails/18196_thumbnail.png</td>\n",
       "      <td>18196</td>\n",
       "      <td>HGSC</td>\n",
       "      <td>64620</td>\n",
       "      <td>28043</td>\n",
       "      <td>False</td>\n",
       "      <td>dataset/train_images/18196.png</td>\n",
       "      <td>infer_seg/18196_seg.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>dataset/train_thumbnails/64111_thumbnail.png</td>\n",
       "      <td>64111</td>\n",
       "      <td>HGSC</td>\n",
       "      <td>15549</td>\n",
       "      <td>8129</td>\n",
       "      <td>False</td>\n",
       "      <td>dataset/train_images/64111.png</td>\n",
       "      <td>infer_seg/64111_seg.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>dataset/train_thumbnails/45630_thumbnail.png</td>\n",
       "      <td>45630</td>\n",
       "      <td>EC</td>\n",
       "      <td>65872</td>\n",
       "      <td>46075</td>\n",
       "      <td>False</td>\n",
       "      <td>dataset/train_images/45630.png</td>\n",
       "      <td>infer_seg/45630_seg.npy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>513 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            thumbnails_file_paths image_id label  image_width  \\\n",
       "0     dataset/train_thumbnails/6175_thumbnail.png     6175  HGSC        60306   \n",
       "1    dataset/train_thumbnails/27739_thumbnail.png    27739  HGSC        80170   \n",
       "2    dataset/train_thumbnails/45254_thumbnail.png    45254    EC        62667   \n",
       "3    dataset/train_thumbnails/51021_thumbnail.png    51021  HGSC        72720   \n",
       "4     dataset/train_thumbnails/5251_thumbnail.png     5251  HGSC       105763   \n",
       "..                                            ...      ...   ...          ...   \n",
       "508   dataset/train_thumbnails/5114_thumbnail.png     5114  HGSC        33646   \n",
       "509  dataset/train_thumbnails/47105_thumbnail.png    47105    EC        39020   \n",
       "510  dataset/train_thumbnails/18196_thumbnail.png    18196  HGSC        64620   \n",
       "511  dataset/train_thumbnails/64111_thumbnail.png    64111  HGSC        15549   \n",
       "512  dataset/train_thumbnails/45630_thumbnail.png    45630    EC        65872   \n",
       "\n",
       "     image_height  is_tma                       file_path  \\\n",
       "0           29620   False   dataset/train_images/6175.png   \n",
       "1           41514   False  dataset/train_images/27739.png   \n",
       "2           14444   False  dataset/train_images/45254.png   \n",
       "3           37900   False  dataset/train_images/51021.png   \n",
       "4           18704   False   dataset/train_images/5251.png   \n",
       "..            ...     ...                             ...   \n",
       "508         29171   False   dataset/train_images/5114.png   \n",
       "509         39353   False  dataset/train_images/47105.png   \n",
       "510         28043   False  dataset/train_images/18196.png   \n",
       "511          8129   False  dataset/train_images/64111.png   \n",
       "512         46075   False  dataset/train_images/45630.png   \n",
       "\n",
       "                   seg_paths  \n",
       "0     infer_seg/6175_seg.npy  \n",
       "1    infer_seg/27739_seg.npy  \n",
       "2    infer_seg/45254_seg.npy  \n",
       "3    infer_seg/51021_seg.npy  \n",
       "4     infer_seg/5251_seg.npy  \n",
       "..                       ...  \n",
       "508   infer_seg/5114_seg.npy  \n",
       "509  infer_seg/47105_seg.npy  \n",
       "510  infer_seg/18196_seg.npy  \n",
       "511  infer_seg/64111_seg.npy  \n",
       "512  infer_seg/45630_seg.npy  \n",
       "\n",
       "[513 rows x 8 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = seg_infer(test_df)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0e7011dc-c63d-4360-af4f-c1441a3c6c9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GeM(nn.Module):\n",
    "    def __init__(self, p=3, eps=1e-6):\n",
    "        super(GeM, self).__init__()\n",
    "        self.p = nn.Parameter(torch.ones(1)*p)\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.gem(x, p=self.p, eps=self.eps)\n",
    "        \n",
    "    def gem(self, x, p=3, eps=1e-6):\n",
    "        return F.avg_pool2d(x.clamp(min=eps).pow(p), (x.size(-2), x.size(-1))).pow(1./p)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + \\\n",
    "                '(' + 'p=' + '{:.4f}'.format(self.p.data.tolist()[0]) + \\\n",
    "                ', ' + 'eps=' + str(self.eps) + ')'\n",
    "    \n",
    "    \n",
    "class UBCModel(nn.Module):\n",
    "    def __init__(self, model_name, num_classes=5, pretrained=False, checkpoint_path=None):\n",
    "        super(UBCModel, self).__init__()\n",
    "        self.model = timm.create_model(model_name, pretrained=pretrained)\n",
    "\n",
    "        in_features = self.model.classifier.in_features\n",
    "        self.model.classifier = nn.Identity()\n",
    "        self.model.global_pool = nn.Identity()\n",
    "        self.pooling = GeM()\n",
    "        self.linear = nn.Linear(in_features, num_classes)\n",
    "#         self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, images):\n",
    "        features = self.model(images)\n",
    "        pooled_features = self.pooling(features).flatten(1)\n",
    "        output = self.linear(pooled_features)\n",
    "        return output\n",
    "    \n",
    "class UBCClcDataset(Dataset):\n",
    "    def __init__(self, df, transforms=None):\n",
    "        self.df = df\n",
    "        self.file_names = df[\"tile_file_paths\"].values\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.file_names[index]\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        if self.transforms:\n",
    "            img = self.transforms(image=img)[\"image\"]\n",
    "\n",
    "        return {\"image\": img}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0f96aa0f-978e-4775-b7e2-6ac26f5ade5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def infer_clc(tile_df, model):\n",
    "\n",
    "\n",
    "    def get_transforms():\n",
    "        return A.Compose(\n",
    "            [\n",
    "                A.Resize(CFG.img_size, CFG.img_size),\n",
    "                A.Normalize(\n",
    "                    mean=[0.485, 0.456, 0.406],\n",
    "                    std=[0.229, 0.224, 0.225],\n",
    "                    max_pixel_value=255.0,\n",
    "                    p=1.0,\n",
    "                ),\n",
    "                ToTensorV2(),\n",
    "            ],\n",
    "            p=1.0,\n",
    "        )\n",
    "\n",
    "    test_dataset = UBCClcDataset(tile_df, transforms=get_transforms())\n",
    "    test_loader = DataLoader(test_dataset, batch_size=4, \n",
    "                              num_workers=4, shuffle=False, pin_memory=True)\n",
    "    probs = []\n",
    "    for index, data in enumerate(test_loader):\n",
    "        data = data[\"image\"].to(device)\n",
    "        outputs = model(data)\n",
    "        p = torch.sigmoid(outputs)\n",
    "        p = p.detach().cpu().numpy()\n",
    "        probs.append(p)\n",
    "        \n",
    "        del data\n",
    "        del outputs\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "    probs = np.concatenate(probs)\n",
    "    probs = np.mean(probs,0)\n",
    "    max_index = np.argmax(probs)\n",
    "    \n",
    "    label_dict = {\n",
    "        0 : \"CC\",\n",
    "        1 : \"EC\",\n",
    "        2 : \"HGSC\",\n",
    "        3 : \"LGSC\",\n",
    "        4 : \"MC\"\n",
    "    }\n",
    "    \n",
    "    max_prob = probs[max_index]\n",
    "\n",
    "    if max_prob > 0.25:\n",
    "        pred_class = label_dict[max_index]\n",
    "    else:\n",
    "        pred_class = \"Other\"\n",
    "    return pred_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8885f418-6496-43c3-a415-c1a04ad26b1c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shigengtian/anaconda3/lib/python3.11/site-packages/timm/models/_factory.py:114: UserWarning: Mapping deprecated model name tf_efficientnetv2_s_in21ft1k to current tf_efficientnetv2_s.in21k_ft_in1k.\n",
      "  model = create_fn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights loaded\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "tile_size = 2048\n",
    "\n",
    "clc_weight = \"exp-06/fold-0.pth\"\n",
    "model = UBCModel(\"tf_efficientnetv2_s_in21ft1k\")\n",
    "model.to(device)\n",
    "model.load_state_dict(torch.load(clc_weight))\n",
    "print(\"weights loaded\")\n",
    "rst_image_ids = []\n",
    "rst_labels=[]\n",
    "for index, row in test_df.iterrows():\n",
    "    save_path = \"tiles\"\n",
    "\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    \n",
    "    _img_ids = []\n",
    "    _tile_file_paths = []\n",
    "    \n",
    "    image_id = row[\"image_id\"]\n",
    "    img_path = row[\"file_path\"]\n",
    "    mask_path = row[\"seg_paths\"]\n",
    "    is_tma = row[\"is_tma\"]\n",
    "    \n",
    "    \n",
    "    img = cv2.imread(str(img_path))\n",
    "    \n",
    "    height, width = img.shape[:2]\n",
    "    mask = np.load(str(mask_path))\n",
    "    mask = cv2.resize(mask, (width, height),interpolation=cv2.INTER_NEAREST)\n",
    "    \n",
    "    rows = height // tile_size\n",
    "    cols = width // tile_size\n",
    "    print(is_tma)\n",
    "#     if is_tma:\n",
    "#         tile = cv2.imread(img_path)\n",
    "#         tile = cv2.resize(tile, (512, 512), interpolation=cv2.INTER_NEAREST)\n",
    "#         tile_filename = f\"{image_id}.png\"\n",
    "#         tile_path = f\"{save_path}/{tile_filename}\"\n",
    "#         cv2.imwrite(tile_path, tile)\n",
    "#         _img_ids.append(image_id)\n",
    "#         _tile_file_paths.append(tile_path)\n",
    "#         del tile\n",
    "#         gc.collect()\n",
    "#         pass\n",
    "#     else:\n",
    "#         for i in range(rows):\n",
    "#             for j in range(cols):\n",
    "#                 tile_mask = mask[\n",
    "#                     i * tile_size : (i + 1) * tile_size,\n",
    "#                     j * tile_size : (j + 1) * tile_size,\n",
    "#                 ]\n",
    "#                 true_percentage = tile_mask.sum() / tile_mask.size\n",
    "#                 if true_percentage < 0.5:\n",
    "#                     continue\n",
    "\n",
    "#                 tile = img[\n",
    "#                     i * tile_size : (i + 1) * tile_size,\n",
    "#                     j * tile_size : (j + 1) * tile_size,\n",
    "#                 ]\n",
    "#                 tile = cv2.resize(tile, (512, 512), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "#                 tile_filename = f\"{image_id}_{i}_{j}.png\"\n",
    "#                 tile_path = f\"{save_path}/{tile_filename}\"\n",
    "#                 cv2.imwrite(tile_path, tile)\n",
    "#                 _img_ids.append(image_id)\n",
    "#                 _tile_file_paths.append(tile_path)\n",
    "#                 del tile\n",
    "#                 gc.collect()\n",
    "                \n",
    "                \n",
    "\n",
    "#     del img\n",
    "#     del mask\n",
    "#     gc.collect()\n",
    "    \n",
    "#     tile_df = pd.DataFrame()\n",
    "#     tile_df[\"image_id\"] = _img_ids\n",
    "#     tile_df[\"tile_file_paths\"] = _tile_file_paths\n",
    "#     print(tile_df)\n",
    "#     pred_class = infer_clc(tile_df, model)\n",
    "#     rst_image_ids.append(int(image_id))\n",
    "#     rst_labels.append(pred_class)\n",
    "#     shutil.rmtree(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7369ce-a033-4f7c-a58e-867148847e19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
